{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Question 2.1 Skeleton Code\n",
    "\n",
    "Here you should implement and evaluate the k-NN classifier.\n",
    "'''\n",
    "\n",
    "import data\n",
    "import numpy as np\n",
    "# Import pyplot - plt.imshow is useful!\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class KNearestNeighbor(object):\n",
    "    '''\n",
    "    K Nearest Neighbor classifier\n",
    "    '''\n",
    "\n",
    "    def __init__(self, train_data, train_labels):\n",
    "        from scipy import stats\n",
    "        self.train_data = train_data\n",
    "        self.train_norm = (self.train_data**2).sum(axis=1).reshape(-1,1)\n",
    "        self.train_labels = train_labels\n",
    "        self.prior_count = {}\n",
    "        # keep track of the prior probability\n",
    "        unique, counts = np.unique(train_labels, return_counts=True)\n",
    "        for i in range(len(unique)):\n",
    "            self.prior_count[unique[i]] = counts[i]\n",
    "        \n",
    "\n",
    "    def l2_distance(self, test_point):\n",
    "        '''\n",
    "        Compute L2 distance between test point and each training point\n",
    "        \n",
    "        Input: test_point is a 1d numpy array\n",
    "        Output: dist is a numpy array containing the distances between the test point and each training point\n",
    "        '''\n",
    "        # Process test point shape\n",
    "        test_point = np.squeeze(test_point)\n",
    "        if test_point.ndim == 1:\n",
    "            test_point = test_point.reshape(1, -1)\n",
    "        assert test_point.shape[1] == self.train_data.shape[1]\n",
    "\n",
    "        # Compute squared distance\n",
    "        test_norm = (test_point**2).sum(axis=1).reshape(1,-1)\n",
    "        dist = self.train_norm + test_norm - 2*self.train_data.dot(test_point.transpose())\n",
    "        return np.squeeze(dist)\n",
    "\n",
    "    def query_knn(self, test_point, k):\n",
    "        '''\n",
    "        Query a single test point using the k-NN algorithm\n",
    "\n",
    "        You should return the digit label provided by the algorithm\n",
    "        '''\n",
    "        from scipy import stats\n",
    "        dist = self.l2_distance(test_point)\n",
    "        ind = np.argpartition(dist, k)[:k]\n",
    "        nn = self.train_labels[ind]\n",
    "        digit, _ = stats.mode(nn)\n",
    "        if len(digit) > 1:\n",
    "            # break the tie with prior probability\n",
    "            return max(digit, key = lambda digit: self.prior_count[digit])\n",
    "        return digit[0]\n",
    "\n",
    "def cross_validation(train_data, train_labels, k_range=np.arange(1,16)):\n",
    "    '''\n",
    "    Perform 10-fold cross validation to find the best value for k\n",
    "\n",
    "    Note: Previously this function took knn as an argument instead of train_data,train_labels.\n",
    "    The intention was for students to take the training data from the knn object - this should be clearer\n",
    "    from the new function signature.\n",
    "    '''\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits = 10, shuffle=True)\n",
    "    acc = {}\n",
    "    for k in k_range:\n",
    "        # Loop over folds\n",
    "        # Evaluate k-NN\n",
    "        acc[k] = []\n",
    "        for train_index, test_index in kf.split(train_labels):\n",
    "            X_train, X_test = train_data[train_index], train_data[test_index]\n",
    "            y_train, y_test = train_labels[train_index], train_labels[test_index]\n",
    "            knn = KNearestNeighbor(X_train, y_train)\n",
    "            acc[k].append(classification_accuracy(knn, k, X_test, y_test))\n",
    "        acc[k] = np.mean(acc[k])\n",
    "    K = max(k_range, key = lambda k: acc[k])\n",
    "    return K, acc[K]\n",
    "            \n",
    "def classification_accuracy(knn, k, eval_data, eval_labels):\n",
    "    '''\n",
    "    Evaluate the classification accuracy of knn on the given 'eval_data'\n",
    "    using the labels\n",
    "    '''\n",
    "    sample_size = eval_labels.shape[0]\n",
    "    hit = 0\n",
    "    for i in range(sample_size):\n",
    "        if knn.query_knn(eval_data[i], k) == eval_labels[i]:\n",
    "            hit += 1\n",
    "    return hit / sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN-1 train accuracy: 1.0\n",
      "KNN-1 test accuracy: 0.96875\n",
      "KNN-15 train accuracy: 0.9594285714285714\n",
      "KNN-15 test accuracy: 0.9585\n",
      "K: 3, trainset accuracy: 0.9834285714285714, \n",
      "average accuracy across folds: 0.9637142857142857, test accuracy: 0.96975\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    train_data, train_labels, test_data, test_labels = data.load_all_data('data')\n",
    "    knn = KNearestNeighbor(train_data, train_labels)\n",
    "\n",
    "    # Q1\n",
    "    # compute accuracy for knn-1\n",
    "    accuracy = classification_accuracy(knn, 1, train_data, train_labels)\n",
    "    print(\"KNN-1 train accuracy: {}\".format(accuracy))\n",
    "    \n",
    "    accuracy = classification_accuracy(knn, 1, test_data, test_labels)\n",
    "    print(\"KNN-1 test accuracy: {}\".format(accuracy))\n",
    "    \n",
    "    # compute accuracy for knn-15\n",
    "    accuracy = classification_accuracy(knn, 15, train_data, train_labels)\n",
    "    print(\"KNN-15 train accuracy: {}\".format(accuracy))\n",
    "    \n",
    "    accuracy = classification_accuracy(knn, 15, test_data, test_labels)\n",
    "    print(\"KNN-15 test accuracy: {}\".format(accuracy))\n",
    "    \n",
    "    # Q2 as seen in class KNearestNeighbor\n",
    "    \n",
    "    # Q3\n",
    "    K, folds_acc = cross_validation(train_data, train_labels)\n",
    "    train_acc = classification_accuracy(knn, K, train_data, train_labels)\n",
    "    test_acc = classification_accuracy(knn, K, test_data, test_labels)\n",
    "    print(\"K: {}, trainset accuracy: {}, \\naverage accuracy across folds: {}, test accuracy: {}\".format(K, train_acc, folds_acc, test_acc))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
