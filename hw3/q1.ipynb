{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Question 1 Skeleton Code\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def load_data():\n",
    "    # import and filter data\n",
    "    newsgroups_train = fetch_20newsgroups(subset='train',remove=('headers', 'footers', 'quotes'))\n",
    "    newsgroups_test = fetch_20newsgroups(subset='test',remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "    return newsgroups_train, newsgroups_test\n",
    "\n",
    "# remove punctuation, stop words, and stemmize the words\n",
    "def preprocess(data):\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    stop = set(list(string.punctuation) + list(stopwords.words('english')))\n",
    "    word_tokens = [[token for token in nltk.word_tokenize(sentence) if token not in stop] for sentence in data]\n",
    "    stemmed = [[stemmer.stem(token) for token in tokens] for tokens in word_tokens]\n",
    "    return [' '.join(tokens) for tokens in stemmed]\n",
    "\n",
    "def bow_features(train_data, test_data):\n",
    "    # Bag-of-words representation\n",
    "    bow_vectorize = CountVectorizer()\n",
    "    bow_train = bow_vectorize.fit_transform(train_data.data) #bag-of-word features for training data\n",
    "    bow_test = bow_vectorize.transform(test_data.data)\n",
    "    feature_names = bow_vectorize.get_feature_names() #converts feature index to the word it represents.\n",
    "    shape = bow_train.shape\n",
    "    print('{} train data points.'.format(shape[0]))\n",
    "    print('{} feature dimension.'.format(shape[1]))\n",
    "    print('Most common word in training set is \"{}\"'.format(feature_names[bow_train.sum(axis=0).argmax()]))\n",
    "    return bow_train, bow_test, feature_names\n",
    "\n",
    "def tf_idf_features(train_data, test_data):\n",
    "    # Bag-of-words representation\n",
    "    tf_idf_vectorize = TfidfVectorizer()\n",
    "    tf_idf_train = tf_idf_vectorize.fit_transform(train_data.data) #bag-of-word features for training data\n",
    "    feature_names = tf_idf_vectorize.get_feature_names() #converts feature index to the word it represents.\n",
    "    tf_idf_test = tf_idf_vectorize.transform(test_data.data)\n",
    "    return tf_idf_train, tf_idf_test, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 train data points.\n",
      "86849 feature dimension.\n",
      "Most common word in training set is \"ax\"\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = load_data()\n",
    "train_data.data = preprocess(train_data.data)\n",
    "test_data.data = preprocess(test_data.data) \n",
    "train_bow, test_bow, feature_names = bow_features(train_data, test_data)\n",
    "train_tf_idf, test_tf_idf, feature_names = tf_idf_features(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB baseline train accuracy = 0.5981085380943963\n",
      "BernoulliNB baseline test accuracy = 0.46587891662241104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "def bnb_baseline(bow_train, train_labels, bow_test, test_labels):\n",
    "    # training the baseline model\n",
    "    binary_train = (bow_train>0).astype(int)\n",
    "    binary_test = (bow_test>0).astype(int)\n",
    "\n",
    "    model = BernoulliNB()\n",
    "    model.fit(binary_train, train_labels)\n",
    "\n",
    "    #evaluate the baseline model\n",
    "    train_pred = model.predict(binary_train)\n",
    "    print('BernoulliNB baseline train accuracy = {}'.format((train_pred == train_labels).mean()))\n",
    "    test_pred = model.predict(binary_test)\n",
    "    print('BernoulliNB baseline test accuracy = {}'.format((test_pred == test_labels).mean()))\n",
    "    return model\n",
    "\n",
    "bnb_model = bnb_baseline(train_bow, train_data.target, test_bow, test_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest baseline train accuracy = 0.9742796535266042\n",
      "RandomForest baseline test accuracy = 0.6411311736590547\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def rf_baseline(tf_idf_train, train_labels, tf_idf_test, test_labels):\n",
    "    search_grid = {'n_estimators': [400, 800, 1200]}\n",
    "    model = RandomForestClassifier(n_jobs = 8)\n",
    "    grid_clf = GridSearchCV(model, param_grid = search_grid)\n",
    "    grid_clf.fit(tf_idf_train, train_labels)\n",
    "\n",
    "    #evaluate the baseline model\n",
    "    train_pred = grid_clf.predict(tf_idf_train)\n",
    "    print('RandomForest baseline train accuracy = {}'.format((train_pred == train_labels).mean()))\n",
    "    test_pred = grid_clf.predict(tf_idf_test)\n",
    "    print('RandomForest baseline test accuracy = {}'.format((test_pred == test_labels).mean()))\n",
    "    return grid_clf.best_estimator_\n",
    "\n",
    "rf_model = rf_baseline(train_tf_idf, train_data.target, test_tf_idf, test_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM baseline train accuracy = 0.9482057627717871\n",
      "SVM baseline test accuracy = 0.5452734997344663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "def svm_baseline(train, train_labels, test, test_labels):\n",
    "    search_grid = {'kernel': ['linear', 'rbf', 'poly'], 'C': [0.1, 1, 10]}\n",
    "    model = SVC()\n",
    "    grid_clf = GridSearchCV(model, param_grid = search_grid)\n",
    "    grid_clf.fit(train, train_labels)\n",
    "\n",
    "    #evaluate the baseline model\n",
    "    train_pred = grid_clf.predict(train)\n",
    "    print('SVM baseline train accuracy = {}'.format((train_pred == train_labels).mean()))\n",
    "    test_pred = grid_clf.predict(test)\n",
    "    print('SVM baseline test accuracy = {}'.format((test_pred == test_labels).mean()))\n",
    "    return grid_clf.best_estimator_\n",
    "\n",
    "svm_model = svm_baseline(train_bow, train_data.target, test_bow, test_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic baseline train accuracy = 0.9211596252430617\n",
      "Logistic baseline test accuracy = 0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def lgc_baseline(train, train_labels, test, test_labels):\n",
    "    search_grid = {'penalty': ['l1', 'l2'], 'C': [0.1, 1, 10]}\n",
    "    model = LogisticRegression()\n",
    "    grid_clf = GridSearchCV(model, param_grid = search_grid)\n",
    "    grid_clf.fit(train, train_labels)\n",
    "\n",
    "    #evaluate the baseline model\n",
    "    train_pred = grid_clf.predict(train)\n",
    "    print('Logistic baseline train accuracy = {}'.format((train_pred == train_labels).mean()))\n",
    "    test_pred = grid_clf.predict(test)\n",
    "    print('Logistic baseline test accuracy = {}'.format((test_pred == test_labels).mean()))\n",
    "    return grid_clf.best_estimator_\n",
    "\n",
    "lgc_model = lgc_baseline(train_bow, train_data.target, test_bow, test_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred):\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    card = max(y_true + 1)\n",
    "    mat = np.zeros([card, card])\n",
    "    for i in range(len(y_true)):\n",
    "        c_true = y_true[i]\n",
    "        c_pred = y_pred[i]\n",
    "        mat[c_true][c_pred] += 1\n",
    "    return mat\n",
    "# logistic regression has the best performance on test set\n",
    "y_pred = lgc_model.predict(test_tf_idf)\n",
    "confusion_mat = confusion_matrix(test_data.target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "normed_confusion_mat = normalize(confusion_mat, axis=1, norm='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.341692789969\n",
      "0.622107969152\n",
      "0.505076142132\n",
      "0.357142857143\n",
      "0.633766233766\n",
      "0.430379746835\n",
      "0.528205128205\n",
      "0.70202020202\n",
      "0.804020100503\n",
      "0.969773299748\n",
      "0.669172932331\n",
      "0.368686868687\n",
      "0.312977099237\n",
      "0.262626262626\n",
      "0.535532994924\n",
      "0.236180904523\n",
      "0.381868131868\n",
      "0.505319148936\n",
      "0.1\n",
      "0.111553784861\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(normed_confusion_mat[i][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.34169279  0.0031348   0.0031348   0.          0.          0.\n",
      "   0.0031348   0.04075235  0.06583072  0.47335423  0.          0.0031348\n",
      "   0.0031348   0.0031348   0.01253918  0.02194357  0.0031348   0.          0.\n",
      "   0.02194357]\n",
      " [ 0.          0.62210797  0.04113111  0.00257069  0.01285347  0.01799486\n",
      "   0.00257069  0.02570694  0.0437018   0.2159383   0.          0.\n",
      "   0.00771208  0.          0.00771208  0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.04822335  0.50507614  0.03553299  0.04314721  0.00761421\n",
      "   0.          0.0177665   0.05583756  0.27411168  0.          0.\n",
      "   0.00253807  0.          0.01015228  0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.03826531  0.06632653  0.35714286  0.0994898   0.\n",
      "   0.03061224  0.04336735  0.04591837  0.28316327  0.00255102  0.\n",
      "   0.03316327  0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.0025974   0.01038961  0.00519481  0.01558442  0.63376623  0.\n",
      "   0.00779221  0.03116883  0.04935065  0.22857143  0.          0.\n",
      "   0.01038961  0.          0.00519481  0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.11139241  0.06075949  0.          0.01012658  0.43037975\n",
      "   0.00253165  0.02278481  0.06075949  0.29367089  0.          0.\n",
      "   0.00506329  0.          0.00253165  0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.00512821  0.00769231  0.02564103  0.03333333  0.\n",
      "   0.52820513  0.06410256  0.06153846  0.27179487  0.          0.\n",
      "   0.0025641   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.00505051  0.7020202   0.0959596   0.18939394  0.          0.\n",
      "   0.00757576  0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.03266332  0.8040201   0.15829146  0.          0.          0.00251256\n",
      "   0.          0.00251256  0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.00251889  0.          0.          0.          0.\n",
      "   0.00251889  0.00503778  0.01007557  0.9697733   0.01007557  0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.01253133  0.01503759  0.30325815  0.66917293  0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.00252525  0.02020202  0.00252525  0.00252525  0.01515152  0.\n",
      "   0.00505051  0.02272727  0.10858586  0.41666667  0.          0.36868687\n",
      "   0.01767677  0.          0.00505051  0.          0.01262626  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.02290076  0.01272265  0.01526718  0.03053435  0.\n",
      "   0.01526718  0.06361323  0.16284987  0.34860051  0.00254453  0.00763359\n",
      "   0.3129771   0.          0.00508906  0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.00252525  0.00757576  0.          0.          0.          0.\n",
      "   0.00252525  0.07323232  0.11111111  0.52272727  0.00505051  0.\n",
      "   0.00757576  0.26262626  0.00252525  0.          0.00252525  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.02030457  0.          0.          0.          0.\n",
      "   0.00507614  0.03807107  0.08883249  0.29949239  0.          0.\n",
      "   0.00507614  0.00253807  0.53553299  0.          0.00507614  0.          0.\n",
      "   0.        ]\n",
      " [ 0.05025126  0.00251256  0.00502513  0.          0.          0.\n",
      "   0.00251256  0.01256281  0.07286432  0.57286432  0.          0.          0.\n",
      "   0.          0.00502513  0.2361809   0.          0.00251256  0.01005025\n",
      "   0.02763819]\n",
      " [ 0.00274725  0.          0.00274725  0.          0.00274725  0.          0.\n",
      "   0.05494505  0.14285714  0.39285714  0.          0.          0.\n",
      "   0.00274725  0.00549451  0.          0.38186813  0.00274725  0.00274725\n",
      "   0.00549451]\n",
      " [ 0.02393617  0.00265957  0.          0.          0.          0.          0.\n",
      "   0.02393617  0.08244681  0.34574468  0.          0.          0.          0.\n",
      "   0.          0.          0.00531915  0.50531915  0.00797872  0.00265957]\n",
      " [ 0.01612903  0.          0.          0.          0.          0.          0.\n",
      "   0.06129032  0.15806452  0.45483871  0.00322581  0.          0.\n",
      "   0.00322581  0.00322581  0.          0.19032258  0.          0.1\n",
      "   0.00967742]\n",
      " [ 0.09561753  0.01195219  0.          0.          0.          0.          0.\n",
      "   0.04780876  0.09163347  0.52988048  0.          0.          0.00398406\n",
      "   0.00398406  0.00398406  0.04780876  0.04780876  0.00398406  0.\n",
      "   0.11155378]]\n"
     ]
    }
   ],
   "source": [
    "print(normed_confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairwise = np.zeros([20, 20])\n",
    "for i in range(20):\n",
    "    for j in range(20):\n",
    "        if i == j:\n",
    "            continue\n",
    "        pairwise[i][j] = normed_confusion_mat[i][j] * normed_confusion_mat[j][i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 8, 0.003134358661996853]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confuses = []\n",
    "for i in range(20):\n",
    "    j = np.argmax(pairwise[i])\n",
    "    confuses.append([i, j, pairwise[i][j]])\n",
    "# class 7 & 8 have the most pairwise confusion probability\n",
    "max(confuses, key = lambda tri: tri[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
